---
title: "Identifying and extracting spreadsheet data from NHS Digital"
author: "Julian Flowers"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{nhsd data extraction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# Introduction

This script identifies and extracts the spreadsheet data published by NHS Digital for a range of topics. It makes use of functions in the `myScrapers` package which allow us to iteratively parse the NHS Digital website to identify the spreadsheets and csv files attached to statistical publications - https://digital.nhs.uk/data-and-information/publications/statistical


It makes use of 4 functions:

* `get_nhsd_url` which finds urls
* `create_nhsd_url` which creates urls 
* `get_nhsd_csv` which finds spreadsheet links
* `get_nhsd_titles` which finds resource titles



```{r, include = FALSE}

knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE)

if(!require("myScrapers"))devtools::install_github("julianflowers/myScrapers")
library(pacman)
p_load(myScrapers, tidyverse)

```


## Identify root pages for statistical publications

```{r urls}

url <- "https://digital.nhs.uk/search/document-type/publication/publicationStatus/true?page="
urls <- paste0(url, 1:50) ## 1st pages of results
urls1 <- map(urls, function(x) get_nhsd_urls(x))
urls1 <- flatten(urls1)

```


## Create links

```{r}

links <- create_nhsd_urls(urls1)
links



```


We now have a list of all the subpages for each topic.

We can now try and identify all the relevant csv or xlsx files on each page. We can use the `find_nhsd_csv` function for this, and `find_nhsd_titles`  for metadata.

## Find csv/xlsx

```{r}

csv <- map(links, function(x) find_nhsd_csv(x))

titles <- map(links, function(x) get_nhsd_titles(x))

names(csv) <- titles

csv_flat <- flatten(csv)

```

This produces a list of `r length(csv)` sets of csv/xlsx files we can download. There are `r length(csv_flat)` files in all.

We can in read in csv files directly from the link (xlsx files need to be downloaded first). Some are zip files which need to be excluded and handled separately.

```{r}
csvs <- csv_flat %>% .[grepl("csv$", .)] 


head(csvs)

```


```{r}
downloads <- map(csvs[12], read_csv, na = "*")

downloads %>%
  data.frame() %>%
  ggplot(aes(NUMBER_OF_PATIENTS)) +
  geom_histogram(binwidth  = 250) +
  geom_density()

```

We can see some cleaning will be needed to remove excess columns, convert character fields to numeric an so on.


