---
title: "Extracting information from PHE blogs and publications"
author: "Julian Flowers"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{phe blog extraction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  cache = TRUE,
  warning = FALSE, 
  fig.width = 8,
  fig.height = 6
)



```

PHE publishes a range of information to <https://www.gov.uk/phe> inlcuding blogs, statistics and other publications.

This vignette introduces an internal PHE R package `myScrapers` which includes tools to extract published public health information from:

* NHS Digital
* NICE Public Health Guidance
* .GOV.UK

The functions offered include 

* `blog_type_extractor` which pulls a dataframe of blog topics or authors
* `phe_blog_scraper` which allows the user to retrieve the text of blogs by topic into a tidy data frame.
* `phe_pubs` which downloads an interactive table of PHE publications on .GOV.UK
* `get_nhsd_pubs`, `get_NHSD_header`, `get_NHSD_sheets`,`get_NHSD_metadata`,`get_NHSD_header` which can be combined to identify published public health spreadsheets on the NHS Digital website
* `get_nice_guidance` which downloads as a single file, recommendations from NICE public health guidance.

These tools are intended to help text mining and analysis of published content, to assist developing outputs such as products and services catalogues, and to make it easier to identify public health content at NHS Digital.

The functions are assembled as an R package which is currently available on github at https://github.com/julianflowers/myScrapers.


## Getting started

The first step is to install the package. This can be achieved with the code below:

```{r libraries, message=FALSE, warning=FALSE}
library(devtools)
library(pacman)
if(!require("myScrapers"))install_github("julianflowers/myScrapers", build_vignettes =TRUE)

p_load(myScrapers, tidyverse, tidytext, quanteda, Rcrawler)

```


# PHE Blogs

The URL for PHE blogs is "https://publichealthmatters.blog.gov.uk".

We can obtain a table of blog topic categories or authors...

```{r phe-blog-urls, warning=FALSE}

url <- "https://publichealthmatters.blog.gov.uk"
url1 <- paste0(url,  "/page/", 2:73)
urls <- c(url, url1)

cats <- get_blog_categories(urls)
 
cats
```


```{r get-authors, warning=FALSE}

url <- "https://publichealthmatters.blog.gov.uk"

authors <- get_blog_authors(url)
 
authors
```


## Blog text

We can extract blog posts for any given category e.g. *the-week-at-phe*

```{r get-blog-text}
n <- 6
url <- "https://publichealthmatters.blog.gov.uk/category/the-week-at-phe/"
url1 <- paste0(url, "/page/", 2:n)
ifelse( n>1, urls <- c(url, url1), urls <- url)
#cat <- "local-authority-public-health/"
links <- map(urls, function(x) get_blog_links(x))
links1 <-  flatten(links) %>% unique() %>% map_chr(1)
links1 <- links1[-11]
blogs <- map(links1, function(x) get_blog_text(x))
 blogs1 <- map(blogs, data.frame)
 blogs2 <- map_df(blogs1, bind_rows)
colnames(blogs2) <- c("text", "url")
 

palette <- RColorBrewer::brewer.pal(10, rev("Spectral"))

blogs2 %>%
  create_bigrams(text) %>%
  group_by(bigram) %>%
  count(sort=TRUE) %>%
  filter(!bigram %in% c("public health", "we’re pleased", "past week", "phe’s online", "week here’s", "online activity", "kevin fenton", "friday messages", "wishes friday")) %>%
  with(., wordcloud::wordcloud(bigram, n, colors = palette, random.order = FALSE, random.color = FALSE, max.words = "Inf", rot.per = 0.4, scale = c(4, 0.1)))
 
```

or Duncan's friday message

```{r friday-message}
n <- 6
url <- "https://publichealthmatters.blog.gov.uk/category/duncan-selbie-friday-message/"
url1 <- paste0(url, "/page/", 2:n)
ifelse( n>1, urls <- c(url, url1), urls <- url)
#cat <- "local-authority-public-health/"
links <- map(urls, function(x) get_blog_links(x))
links1 <-  flatten(links) %>% unique() %>% map_chr(1)
links1 <- links1[-11]
blogs_ds <- map(links1, function(x) get_blog_text(x))
 blogs_ds1 <- map(blogs, data.frame)
 blogs_ds2 <- map_df(blogs1, bind_rows)
colnames(blogs_ds2) <- c("text", "url")
 

palette <- RColorBrewer::brewer.pal(11, "Spectral")

blogs_ds2 %>%
  create_bigrams(text) %>%
  group_by(bigram) %>%
  count(sort=TRUE) %>%
  ungroup() %>%
  mutate(bigram = tm::removeNumbers(bigram)) %>%
  filter(!bigram %in% c("public health", "we’re pleased", "past week", "phe’s online", "week here’s", "online activity", "friday messages", "wishes friday")) %>%
  with(., wordcloud::wordcloud(bigram, n, colors = palette, random.order = FALSE, random.color = FALSE, max.words = "Inf", rot.per = 0.4, scale = c(4, 0.1)))
 
```


```{r network-plot, fig.height=6, fig.width=8}
library(igraph)
library(ggraph)

bigrams <- create_bigrams(blogs_ds2, text)

bigrams <- bigrams %>%
  separate(url, remove = FALSE, c("root", "name", "cat", "message",  "day", "month", "year" ), sep = "-") %>%
  mutate(year = str_replace_all(year, "/", "")) %>%
  unite(date, day, month, year, sep ="-") %>%
  select(date, bigram, n)

big_count <- bigrams %>%
  mutate(date )
  group_by(date, bigram) %>%
  count(sort = TRUE) %>%
  #separate(bigram, c("word1", "word2")) %>%
  filter(n >1)

create_network_plot(big_count, layout = "graphopt") + 
  theme(legend.position = "bottom") +
  labs(title = "Network plot of Friday messages ")
```



```{r netowrk-quanteda, eval=FALSE}
library(quanteda)
library(tm)

blog_corp <- quanteda::corpus(blogs2$text)
dfm_phe <- quanteda::dfm(blog_corp, remove = c(stopwords("en"), "government", "phe", "health", "uploads", "harlow", "nhs", "england", "the_nhs", "phe_harlow", "attachment_data", "victoria", "london", "swh", "eu"), remove_punct = TRUE, remove_numbers = TRUE, tolower = TRUE, ngrams = 1:2, context = "window") 

feat <- names(topfeatures(dfm_phe, 300))
  
dfm_select(dfm_phe, feat) %>% textplot_network(min_freq = 0.9, omit_isolated = TRUE, vertex_labelfont = "Arial Narrow") +
  labs(title = "Network map of most frequent terms used in remit letters and PHE business plan", 
       subtitle = "2 and 3 word ngrams")

```


## PHE publications

Its hard to get everything PHE has published on .GOV.UK. To assist this process we have written a function which produces an interactive table of all the PHE publications by category (NB at the moment it is over inclusive). This makes use of the `DT` package and allows us to add download options so the data can be downloaded in various forms.

```{r}

phe_cat <- myScrapers::get_phe_catalogue(url = "https://www.gov.uk/government/publications?departments%5B%5D=public-health-england", pages = 2:95)

phe_cat

```

